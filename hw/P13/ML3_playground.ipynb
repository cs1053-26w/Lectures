{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba16250",
   "metadata": {},
   "source": [
    "## ML3 - Machine Learning in Practice; Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cd91b-defb-4a7c-a492-05751b4de84d",
   "metadata": {},
   "source": [
    "#### Goals\n",
    "* Get familiar with tuning hyperparameters and tweaking models\n",
    "* Go through the exercise of finding the \"sweet spot\" between underfitting and overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da81eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda') # nvidia/cuda\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device('mps') # apple\n",
    "else:\n",
    "    'cpu') # no acceleration\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6391b",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 and Display Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CIFAR-10 class names\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# normalize the data to have 0.5 mean and 0.5 standard deviation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 train\n",
    "cifar10_train = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Load CIFAR-10 test data\n",
    "cifar10_test = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Use a small subset for faster training\n",
    "subset_size = 2000 \n",
    "indices = torch.randperm(len(full_dataset))[:subset_size]\n",
    "train_subset = torch.utils.data.Subset(cifar10_train, indices)\n",
    "\n",
    "# Use a small test set so validation is quick\n",
    "subset_size = 256  \n",
    "indices = torch.randperm(len(cifar10_test))[:subset_size]\n",
    "test_subset = torch.utils.data.Subset(cifar10_test, indices)\n",
    "\n",
    "\n",
    "# Display one image from each class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Create a dictionary to track which classes we've seen\n",
    "class_indices = {i: None for i in range(len(classes))}\n",
    "\n",
    "# Find one image from each class\n",
    "for idx, (image, label) in enumerate(train_subset):\n",
    "    if class_indices[label] is None:\n",
    "        class_indices[label] = idx\n",
    "    if all(v is not None for v in class_indices.values()):\n",
    "        break\n",
    "\n",
    "# Plot one image from each class\n",
    "for class_idx in range(len(classes)):\n",
    "    image, label = train_subset[class_indices[class_idx]]\n",
    "    # Denormalize for display: multiply by std and add mean\n",
    "    image = image * 0.5 + 0.5  # undo normalization\n",
    "    image = image.permute(1, 2, 0).numpy()  # Convert to HWC format\n",
    "    axes[class_idx].imshow(image)\n",
    "    axes[class_idx].set_title(f'{classes[label]}')\n",
    "    axes[class_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e2b65",
   "metadata": {},
   "source": [
    "## Part 2: Linear Classifier (Single-layer Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4b444-8954-4e9c-8f88-875907095bf4",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a multi-layer perceptron\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size=3*32*32, hidden_sizes=[512, 256], num_classes=10, dropout_prob=0.2):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Hidden layers with ReLU activation\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_prob))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten the input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Pass through network\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c86a6-599d-4c66-a57d-a29a3c459a21",
   "metadata": {},
   "source": [
    "### Evaluation Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759b771-2670-4d37-a5bc-3c0357c1696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, batch_size=128):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            num_correct += (predicted == labels).sum().item()\n",
    "            num_samples += labels.size(0)\n",
    "            \n",
    "    accuracy = num_correct / num_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585337f7-ff26-42df-9c0a-6d13d6b3bf70",
   "metadata": {},
   "source": [
    "### Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dfbbe8-b20d-47bc-b6a6-81123f841be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, test_dataset, num_epochs=10, batch_size=128, learning_rate=0.01):\n",
    "\n",
    "    # takes care of loading data and creating batches for us\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "    # calculates softmax + cross-entropy loss for us:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # takes care of the gradient updates for us:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # we'll track some history:\n",
    "    train_losses = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set model to \"Train\" mode\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        num_correct = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images) # compute the model outputs\n",
    "            loss = loss_fn(outputs, labels) # calculate the loss\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()   # Clear old gradients\n",
    "            loss.backward()         # Compute gradients\n",
    "            optimizer.step()        # Update parameters\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            # calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            num_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        test_acc = evaluate_model(model, test_dataset)\n",
    "        test_accuracy.append(test_acc)\n",
    "\n",
    "        train_acc = num_correct / len(train_dataset)\n",
    "        train_accuracy.append(train_acc)\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch+1:2d}: Loss = {avg_loss:.4f}, Train Accuracy = {train_acc:.4f}, Test accuracy = {test_acc:.4f}')\n",
    "\n",
    "    return train_losses, train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125dc042-8b19-41e2-b52a-e5495846607b",
   "metadata": {},
   "source": [
    "### Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefe697",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters - tune these to try to get a good model that doesn't overfit!\n",
    "hidden_sizes = [512, 256]\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Create MLP model and move to device\n",
    "mlp_model = MLPClassifier(input_size=3*32*32, hidden_sizes=hidden_sizes, num_classes=10).to(device)\n",
    "print(f'MLP model created:')\n",
    "print(mlp_model)\n",
    "print(f'Number of parameters: {sum(p.numel() for p in mlp_model.parameters()):,}')\n",
    "print('Training MLP Classifier...')\n",
    "print('='*50)\n",
    "\n",
    "# Train the MLP classifier\n",
    "mlp_train_losses, mlp_train_accs, mlp_test_accs = train_model(\n",
    "    mlp_model, data_subset, test_subset,\n",
    "    num_epochs=num_epochs, \n",
    "    batch_size=batch_size, \n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "print('='*50)\n",
    "print(f'MLP Classifier - Final Train Accuracy: {mlp_train_accs[-1]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MLP classifier training\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Training loss\n",
    "ax = axes[0]\n",
    "ax.plot(mlp_train_losses, marker='o', linewidth=2, markersize=4)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Training Loss', fontsize=12)\n",
    "ax.set_title('MLP Classifier: Training Loss', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Train and test accuracy\n",
    "ax = axes[1]\n",
    "ax.plot(mlp_train_accs, marker='o', linewidth=2, markersize=4, color='tab:orange', label=\"Train Accuracy\")\n",
    "ax.plot(mlp_test_accs, marker='o', linewidth=2, markersize=4, color='tab:blue', label=\"Test Accuracy\")\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('MLP Classifier: Train Accuracy', fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mlp_classifier_training.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
