{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3109b7e-0092-47a3-aca2-288e745731ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lecture 6 - Parametric Transformations; Feature Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efd636-c09e-4d1f-a828-33e0fcc75686",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Goals\n",
    "* Understand the mathematical framework for (linear) geometric transformations on images (image warping).\n",
    "* Know what is possible with 2D linear transformations (scale, shear, rotation)\n",
    "* Understand the motivation and math behind homogeneous coordinates.\n",
    "* Know what is possible with 2D affine transformations (all of the above, plus translation)\n",
    "\n",
    "* Understand the concept of invariance as pertains to feature detectors and feature descriptors\n",
    "* Know the how and why of the MOPS feature descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a295613-e6e3-4f35-b603-27b158385acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(\"../src\")\n",
    "if (src_path not in sys.path):\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Library imports\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage as skim\n",
    "import cv2\n",
    "\n",
    "# codebase imports\n",
    "import util\n",
    "import filtering\n",
    "import features\n",
    "import geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed4ad7-132d-4906-8a67-fae476b90b39",
   "metadata": {},
   "source": [
    "#### Plan\n",
    "\n",
    "* 2D linear transformations\n",
    "* Affine transformations\n",
    "* MOPS descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ef08e-539c-4af6-9453-032e8eb8e287",
   "metadata": {},
   "source": [
    "##### Homework Problem 1\n",
    "Comment on whether (or the extent to which) the Harris corner detector is robust to each of the following transformations. In other words, which of these will not affect which points will be found as corners by the Harris detector? If the detector is almost but not quite completely robust to a given change, comment on this. Assume edge effects and intensity clipping are not an issue.\n",
    "1. Intensity shift: $I(x, y)' = I(x, y) + 20$\n",
    "2. Intensity scale: $I(x, y)' = 1.2 I(x, y)$\n",
    "3. Scaling: $I(x, y)' = I(0.5x, 0.5y)$\n",
    "4. Translation $I(x, y)' = I(x - 10, y)$\n",
    "5. Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71377d-2c64-4397-87d2-e98832f981ad",
   "metadata": {},
   "source": [
    "### A Mathematical Digression: Geometric Transformations\n",
    "\n",
    "Notice that I ran out of math in the last subproblem above - how do I write this down? We've reached the point where it becomes nicer to talk about geometric transformations using the language of linear algebra.\n",
    "\n",
    "Whiteboard linear algebra review:\n",
    "* A 2x2 matrix is a mapping from points to points\n",
    "* You can interpret it two ways:\n",
    "    * Where does it send a point?\n",
    "    * What coordinate system does it translate points *from*? This is the change-of-basis vew.\n",
    "* Transformations can compose (they are linear!). If you let M = AB and apply it to Mx, then B happens first, then A!\n",
    "    * Sometimes this matters, since matrix multiplication doesn't commute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc867b5-23a6-4b4f-a0e5-e5acb6e85338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geometry\n",
    "ferris = imageio.imread(\"../data/L06/tx.png\").astype(np.float32) / 255\n",
    "ferris = skim.transform.rescale(ferris[:,:,:3], (0.5, 0.5, 1))\n",
    "\n",
    "H, W = ferris.shape[:2]\n",
    "util.imshow_truesize(ferris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba6a76-9a28-4811-8899-2c88e289fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_ferris(tx, **kwargs):\n",
    "    fw = geometry.warp(ferris, M, **kwargs)\n",
    "    util.imshow_truesize(fw)\n",
    "\n",
    "M = np.array([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(W, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d5a3c-8dd7-4688-b2c2-a20782853fe4",
   "metadata": {},
   "source": [
    "##### Homework Problems 2-5\n",
    "\n",
    "**Important note: the coordinate system conventions here differ from the homework! Here, (0, 0) is at the top left and y points down In the HW visualizations, the origin is at the bottom left and y points up.**\n",
    "\n",
    "2. Scale uniformly by a factor of 1.3:\n",
    "\n",
    "   ![](../data/L06/tx1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22063a-554c-4759-9e7a-b59d4f3209e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [1.3, 0.0],\n",
    "    [0.0, 1.3]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(int(W*1.3), int(H*1.3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310b4d8-1f5f-40a7-8cda-d5f78e25ec30",
   "metadata": {},
   "source": [
    "3. Scale by a factor of 2 in only the $x$ direction:\n",
    "\n",
    "    ![](../data/L06/tx2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8074194-fa25-48bf-8ce6-df70e33be9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [2.0, 0.0],\n",
    "    [0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(W*2, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5492de0-af5f-417e-b583-3c22c86bc6df",
   "metadata": {},
   "source": [
    "4. Skew or *shear* the image so the top row of pixels is shifted over by 1/4 of the image's height.\n",
    "\n",
    "    ![](../data/L06/tx3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a3c56-2706-471c-bdea-724bc4b98037",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [1.0, 0.25],\n",
    "    [0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(int(W*1.25), H))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e413dd-c8b3-4780-9af6-e1fb37c5e17d",
   "metadata": {},
   "source": [
    "5. Rotate the image counter-clockwise by 30 degrees:\n",
    "\n",
    "    ![](../data/L06/tx4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0b6d9-e010-4fa5-bdb5-eade6688f37c",
   "metadata": {},
   "source": [
    "* Rotation matrices: to rotate $\\theta$ counter-clockwise, the matrix is:\n",
    "  $$\n",
    "  \\begin{bmatrix}\n",
    "  \\cos \\theta & \\sin \\theta \\\\\n",
    "  -\\sin \\theta & \\cos \\theta \\\\\n",
    "  \\end{bmatrix}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72f15f-ee4d-4bf7-bff6-ffa6ec4f5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad30 = np.radians(30)\n",
    "\n",
    "M = np.array([\n",
    "    [np.cos(rad30), np.sin(rad30)],\n",
    "    [-np.sin(rad30), np.cos(rad30)]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(int(W), int(H*1.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f94f9bc-01b9-42db-9457-525b01d324f6",
   "metadata": {},
   "source": [
    "6. Translate the image up and right by (say) 40 pixels:\n",
    "![](../data/L06/tx5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1b976-a7b6-4e73-94fb-f54fa2111020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa65a53-ed5c-4a92-a5aa-c55edc651385",
   "metadata": {},
   "source": [
    "Scott is the worst. This one's impossible!\n",
    "\n",
    "Proof: no matrix can move (0, 0) to anywhere but (0, 0).\n",
    "\n",
    "Hack: add a column! This is the same hack as the bias trick from ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110a5fc-0c2f-47f5-99bd-5dc896b96129",
   "metadata": {},
   "source": [
    "Whiteboard: Affine transformations\n",
    "\n",
    "\n",
    "Just like 2x2 linear transformations can be seen as a change of basis, affine can be seen as a **change of frame**, where the origin may also \n",
    "move. This will come back to haunt us later!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a9690-9d17-422f-af51-5962ca8f7bb1",
   "metadata": {},
   "source": [
    "### Back to the Features!\n",
    "\n",
    "For our feature descriptors, we agreed that a patch of pixels is more unique than a single pixel value. Let's start there, and add invariances to the following:\n",
    "\n",
    "* Rotation\n",
    "* (some) intensity shifts and scales ($I' = aI + b$, sort of)\n",
    "* Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936bb27-fe38-47d7-9e37-cb698ae16161",
   "metadata": {},
   "source": [
    "#### The MOPS Feature descriptor\n",
    "Multi-scale oriented patches\n",
    "\n",
    "* Rotation: rotate the gradient direction to angle 0 (horizontal, presumably)\n",
    "* Intensity: subtract mean and divide by standard deviation\n",
    "* Scale: run it on a Gaussian pyramid\n",
    "\n",
    "But how do we even extract a patch in the first place?\n",
    "\n",
    "(**whiteboard**: patch extraction transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418a817-5bf1-4bcc-94df-95362c87530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import features\n",
    "\n",
    "h = imageio.imread(\"../data/harris_crop.jpg\")\n",
    "h = skim.color.rgb2gray(h.astype(np.float32) / 255)\n",
    "\n",
    "corner_mask = features.harris_corners(h, 0.1)\n",
    "plt.imshow(corner_mask)\n",
    "features.get_harris_points(corner_mask).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3930f76-f77e-4e60-a14c-eee8e2dbb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = [59,  32]\n",
    "util.imshow_gray(h)\n",
    "plt.plot(x, y, 'ro', markersize=2)  # 'ro' = red circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ba151-f136-48a3-9e1e-2794ee36ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "util.imshow_gray(features.extract_MOPS(h, (y, x)))\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
