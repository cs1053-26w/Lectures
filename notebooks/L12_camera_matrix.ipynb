{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3109b7e-0092-47a3-aca2-288e745731ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lecture 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0357b50-2962-423e-85f1-80217ec3d134",
   "metadata": {},
   "source": [
    "#### Announcements\n",
    "* Project 2 due tonight! How's it going?\n",
    "* Project 3 out tomorrow; we'll cover plane sweep stereo in tomorrow's class\n",
    "* You can still respond to my Week 2 feedback email if you haven't already!\n",
    "* I think I fixed the github classroom uv issue for projects 2 and 3\n",
    "  * If you created your repo before the fix, it may apply. You can edit .github/workflows/classroom.yml to add these lines before the `- name: Checkout code` line:\n",
    "    ```yaml\n",
    "    - name: Install the latest version of uv\n",
    "      uses: astral-sh/setup-uv@v7\n",
    "    ```\n",
    "    \n",
    "* Week 2 Checkins today\n",
    "* Today's tea: Nepal Imperial Black or Four Seasons Oolong?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efd636-c09e-4d1f-a828-33e0fcc75686",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Goals\n",
    "* Be able to implement a basic rectified stereo depth estimation routine.\n",
    "* Understand why matching is the hard part of stereo vision.\n",
    "* Know the definition and formation of the stereo cost volume.\n",
    "* Know why and how to use the normalized cross-correlation cost function for stereo matching.\n",
    "* Understand the construction of the **intrinsic** and **extrinsic** camera matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a295613-e6e3-4f35-b603-27b158385acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(\"../src\")\n",
    "if (src_path not in sys.path):\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Library imports\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as skim\n",
    "import cv2\n",
    "\n",
    "# codebase imports\n",
    "import util\n",
    "import filtering\n",
    "import features\n",
    "import geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70da82-3173-45ef-9ee1-47e9da0ff1ec",
   "metadata": {},
   "source": [
    "#### Outline\n",
    "\n",
    "* Rectified stereo:\n",
    "\n",
    "  * depth from disparity reduces stereo vision to the correspondence problem\n",
    "\n",
    "  * assumed a simple case: this is the **rectified case** where (assumptions)\n",
    "\n",
    "  * correspondence - sounds familiar, but now it's dense. some metrics:\n",
    "\n",
    "    * SSD - sum of squared differences\n",
    "    * SAD - sum of absolute differences\n",
    "    * CC - cross-correlation: filter the right scanline with the left patch; where product is highest, call it a match; in practice, use NCC instead:\n",
    "    * NCC - normalized cross-correlation: standardize (subtract mean, divide by std) patches before multiplication to add invariance to photometric changes\n",
    "\n",
    "  * The **cost volume**: given a matching cost c:\n",
    "\n",
    "    ```\n",
    "    for i in rows:\n",
    "      for j in columns:\n",
    "        for d in disparities:\n",
    "          C[i, j, d] = c(img1[i,j], img2[i,j+d])\n",
    "    ```\n",
    "\n",
    "    (note that c will usually look at a patch around img[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406df0f-2ecb-4688-b1a7-e8a68b87912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = util.imread_grayfloat(\"../data/flowers_left.png\")\n",
    "right = util.imread_grayfloat(\"../data/flowers_right.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a4005-2c21-4625-87dc-9781ea5430e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_gray(np.vstack((left, right)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475fdd6-cc3c-4175-a659-f1de4cab9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch = left[115:125, 205:215]\n",
    "# patch = left[55:61, 102:107]\n",
    "patch = left[0:35, 45:80]\n",
    "\n",
    "util.imshow_gray(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef053e92-75e9-4fbf-afc3-39154c6772ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_filter(img, filter):\n",
    "    return cv2.filter2D(img, -1, filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef126e9-9c38-4c17-9cfc-4825d3402fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = patch - patch.mean()\n",
    "xcorr_out = fast_filter(right-right.mean(), patch-patch.mean())\n",
    "plt.imshow(np.vstack([right, xcorr_out/xcorr_out.max()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba059d-6406-4af0-a5d3-6e0d0758dce1",
   "metadata": {},
   "source": [
    "Define some cost functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d9e0a-7dbb-4549-8689-bbd225e11b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def ncc_cost(left_patch, right_patch):\n",
    "    pass # TODO\n",
    "\n",
    "def ssd_cost(left_patch, right_patch):\n",
    "    return np.sum((left_patch - right_patch)**2)\n",
    "\n",
    "def sad_cost(left_patch, right_patch):\n",
    "    return np.sum(np.abs(left_patch - right_patch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d351a72e-b107-430d-b64f-f32b5b62e77a",
   "metadata": {},
   "source": [
    "Compute the cost volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa30ea-a75e-4666-9dba-13f36f292d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = left.shape\n",
    "window = 5\n",
    "hw = window // 2\n",
    "\n",
    "disparity_img = np.zeros_like(left)\n",
    "\n",
    "disparity_limit = 60\n",
    "\n",
    "for i in tqdm.tqdm(range(hw, H-hw)): # for each row\n",
    "    low_i = i-hw\n",
    "    high_i = i+hw+1\n",
    "    for j in range(hw, W-hw): # for each column within a local window\n",
    "        low_j = j-hw\n",
    "        high_j = j+hw+1\n",
    "        \n",
    "        # extract the left patch:\n",
    "        left_patch = left[low_i:high_i, low_j:high_j] \n",
    "        \n",
    "        costs = 1e5 * np.ones((disparity_limit*2+1)) #initialize costs\n",
    "        for d in range(-disparity_limit, disparity_limit+1): # for each possible disparity\n",
    "            if 0 <= low_j+d and high_j+d <= W:\n",
    "                \n",
    "                # extract a right patch at the current disparity\n",
    "                right_patch = right[low_i:high_i, low_j+d:high_j+d]\n",
    "\n",
    "                # compute the cost\n",
    "                costs[d + disparity_limit] = ssd_cost(left_patch, right_patch)\n",
    "        \n",
    "        # set the disparity to the one with lowest cost\n",
    "        disparity_img[i,j] = np.argmin(costs) - disparity_limit\n",
    "\n",
    "plt.imshow(np.vstack([left, disparity_img/disparity_img.max()]))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b68a4-57ac-4fce-9c65-dd4e3320100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True) # suppress scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d9283-31d1-454b-a5d3-008b735b1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([\n",
    "    [0, 0, -200],\n",
    "    [-20, 50, -200],\n",
    "    [-100, 100, -200]\n",
    "], dtype=np.float64).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de2b03-5c68-43bb-8f3f-a0b80ccaecc8",
   "metadata": {},
   "source": [
    "##### HW #2\n",
    "\n",
    "Suppose a camera is in canonical pose - that is, COP is at world origin, the optical axis runs along the negative z axis, and the projection plane is oriented with $x$ going right and $y$ going up in image space. The focal length of the camera is 100 (this is measured in pixels), and the height and width of the image are also 100. Find the image coordinates (i.e., pixel coordinates that correspond to indices into a numpy array) of the following three 3D points:\n",
    "\n",
    "* Point 1: $[0, 0, 200]$\n",
    "* Point 2: $[-20, 50, 200]$\n",
    "* Point 3: $[-100, 100, 200]$\n",
    "\n",
    "Keep in mind that in numpy arrays, the origin is at the top left and $y$ goes down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d52d63-833d-46c7-bf5d-b7ce43eed9b2",
   "metadata": {},
   "source": [
    "##### HW #3\n",
    "\n",
    "Write down the intrinsics matrix $K$ that maps any point from camera coordinates to image coordinates as above. To check your work, make sure that applying the matrix to the three three points in the previous problem yields the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b55ded-2e65-4870-9f47-a360daad7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW 3: fill in your intrinsics matrix here:\n",
    "K = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "], dtype=np.float64)\n",
    "\n",
    "# HW 3: verify that K @ points yields the expected pixel coordiantes\n",
    "# apply k to points to get points_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136c715-da84-4f58-bfa3-3c7d42232e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4d853d0-e1d2-4ef4-b391-41d4371b162a",
   "metadata": {},
   "source": [
    "Now let's suppose we moved camera. It's now looking at the same points, but the camera center is at $[200, 0, -200]$ and it's rotated 90 degrees \"left\" - in terms of world coordinates, it's now facing down the negative $x$ axis, with $-z$ going right and $+y$ going up\n",
    "\n",
    "##### HW #4\n",
    "4. For world Points 1 and 3 above, give the 3D coordinates of these points in the camera's local coordiante system.\n",
    "\n",
    "##### HW #5\n",
    "5. Give a 4x4 frame (i.e., basis plus origin) matrix that describes this camera's pose; the contents of this matrix should be\n",
    "   $$\n",
    "   \\begin{bmatrix} \\mathbf{u} & \\mathbf{v} & \\mathbf{w} & \\mathbf{p}  \\\\ 0 & 0 & 0 & 1\\end{bmatrix}\n",
    "   $$\n",
    "   where $\\mathbf{u},\\mathbf{v},\\mathbf{w}$ are the (x, y, and z) basis vectors of the camera's local coordinate system, and $\\mathbf{p}$â€‹ is its origin.\n",
    "\n",
    "##### HW #6\n",
    "6. The above frame matrix is the \"frame-to-canonical\" matrix: it converts points represented in the given coordinate frame back into world coordinates. What we want instead for the camera matrix is the opposite: a matrix that transforms world coordinates into camera coordinates. Confirm (using software) that the **inverse** of the matrix that you gave in #5 correctly transforms world coordinates of Points 1 and 3 into the correct camera coordinates you found in #4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c6b00-51c9-43f4-af95-0bfba6364470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW 5: write down the camera frame matrix \n",
    "cam_center = np.array([200, 0, -200], dtype=np.float64)\n",
    "frame = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "], dtype=np.float64)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee885e-bbd7-40aa-bf74-eb39678af491",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67f70f-585f-43b1-92b5-915ae1880750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the 3D points into 3D homogeneous points so they can be translated\n",
    "points_4d = np.ones((4, 3))\n",
    "points_4d[:3, :] = points\n",
    "points_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ae959-2ca6-489f-80bc-f5e9d97d66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW 6: Apply the inverse frame matrix to get world coordinates to camera coordinates\n",
    "# apply inv(frame) to points_4d and normalize; store them in pts_cam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a8eb4-7fee-4c72-b439-7174504dd11d",
   "metadata": {},
   "source": [
    "##### HW #7\n",
    "7. Find (again, using software) the final pixel locations of world points 1 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3fdfaf-eda7-44a9-b79f-c16f3ef42bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the intrinsics 3x4 so it drops the 4th dimension\n",
    "K4d = np.zeros((3, 4))\n",
    "K4d[:3,:3] = K\n",
    "K4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf3e88-139c-4175-a4af-0d88a1789ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW7: find the final pixel locations of the points in the transformed camera\n",
    "# apply K4d to pts_cam and store in pts_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6821a68-0f33-4478-ba98-65a2c2fac28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
