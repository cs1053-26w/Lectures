{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3109b7e-0092-47a3-aca2-288e745731ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lecture 3B - Spatial Frequency, Downsampling, Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5551a96-2bac-4bf9-a5f4-d4f5f0ab4af1",
   "metadata": {},
   "source": [
    "#### Announcements\n",
    "\n",
    "* Adding a little structure for in-class exercises - I'm going to have you work in assigned pairs.\n",
    "   * Randomly assigned - switch it up each week, perhaps?\n",
    " | | |\n",
    " | ------ | ------- |\n",
    " | Ned    | Jacob   |\n",
    " | Charles| Shingo  |\n",
    " | Grayson| Camiel  |\n",
    " | Finn   | Layla   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efd636-c09e-4d1f-a828-33e0fcc75686",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Goals\n",
    "* Know the meaning and construction of \"low pass\" and \"high pass\" filters\n",
    "* Know how to make images smaller:\n",
    "  * The naive way via subsampling (and why this is bad)\n",
    "  * The principled way by downsampling with prefiltering (and why this is better)\n",
    "* Know how to make images bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a295613-e6e3-4f35-b603-27b158385acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(\"../src\")\n",
    "if (src_path not in sys.path):\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Library imports\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as skim\n",
    "import cv2\n",
    "\n",
    "# codebase imports\n",
    "import util\n",
    "import filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c94f74e-ae68-4f33-94a7-d1ba4009740e",
   "metadata": {},
   "source": [
    "## Reminder: The Frequencyometer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b3496-3d80-4136-8a76-a2afaac3728d",
   "metadata": {},
   "source": [
    "The cliff-hanger from last class: how does blurring affect the frequencyometer for an image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e5b13-fd36-4fce-8d10-4b60bfde1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans = imageio.imread(\"../data/beans.jpg\").astype(np.float32) / 255.0\n",
    "bg = skim.color.rgb2gray(beans) # grayscale beans\n",
    "blurry_beans = cv2.GaussianBlur(bg, ksize=(25, 25), sigmaX=4)\n",
    "\n",
    "util.imshow_gray(np.hstack([bg, blurry_beans]))\n",
    "plt.gcf().gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201a8c6-1640-4978-8694-7ed6abc18420",
   "metadata": {},
   "source": [
    "#### Definitions: \"Low-Pass\" and \"High-Pass\" filters\n",
    "\n",
    "Low-pass: allows low frequencies to pass through unaffected, i.e., attenuates high frequencies.\n",
    "* In other words: blur!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa26bf-d89b-42b4-b944-f6bd642c15b3",
   "metadata": {},
   "source": [
    "High-pass: allows high frequencies to pass through unaffected, i.e., attenuates low frequencies.\n",
    "* In other words: derivative, (with slight but common terminology abuse) sobel, or  sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc2f0f-5492-4d5d-b9c7-d5bc6743c2b9",
   "metadata": {},
   "source": [
    "**Question that didn't make it onto the homework:** in what sense is Sobel not truly a high-pass filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402c3316-cf45-472d-81a7-f471653db6e3",
   "metadata": {},
   "source": [
    "##### Homework Problems 3-6\n",
    "\n",
    "(3) Using the language of \"low-\" and \"high-frequency\" image content, explain why sharpening is not the inverse of blurring, and what it accomplishes instead.\n",
    "\n",
    "(4) Consider the original image of beans on the left, and the processed version on the right. Describe what has changed in terms of frequency content.\n",
    "\n",
    "   ![](../data/beans_frequency.jpg)\n",
    "   \n",
    "(5) What's the **maximum** frequency (expressed in full periods per pixel) representable in a 1D image (i.e., a row of pixels)? What does such an image look like?\n",
    "\n",
    "(6) What's the **minimum** frequency representable in a 1D image? What does such an image look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f2446-6534-4abd-aeaa-9c7ad8d43134",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "My image is too big to fit on my screen. For example, suppose beans is 600x600, but I want to display the image in 300x300 pixels. What should I do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df66bc-dcc0-4284-84ac-74e46708f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.shape # beans grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671765e-84bf-4ad2-a3f3-7e4e387e16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_truesize(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c159bc8-5f35-44ce-b0e6-f706e80e69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_truesize(bg[::2,::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e913e-75c9-4d0d-9768-0b5dd40504b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bricks = imageio.imread(\"../data/bricks.jpg\").astype(np.float32) / 255.0\n",
    "plt.imshow(bricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d74f98-f73b-4546-a01e-d1aa088fdf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bricks[::4,::4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a51eb9-3ed7-4ea1-bfb5-25f4028f853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = np.zeros((1, 17))\n",
    "checker[:, ::2] = 1.0\n",
    "util.imshow_gray(checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b85e35-eb1e-4dd2-ae88-49b06da5c85b",
   "metadata": {},
   "source": [
    "##### Homework Problem 7\n",
    "\n",
    "If you walked far away from the above image until you couldn't distinguish individual pixels, what would it look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6e8c3-11b2-4102-b0f3-95bd3f0e9aa5",
   "metadata": {},
   "source": [
    "If you naively subsample the above image, what would it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212a3b4-8de6-415c-8eea-dca4672d8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(checker[:, 0::2], vmin=0, vmax=1, cmap=\"gray\") # force color scale to [0,1] range\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905c382-36be-47db-a8cf-fc3a92026a27",
   "metadata": {},
   "source": [
    "**Whiteboard**: downsampling freqeuncyometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4855549-34d9-41fe-acde-0fbde7ab147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: implement filtering.down_2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584da2e-ddff-442a-9bf1-cb394f7447bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_truesize(np.hstack([bg[::4,::4], filtering.down_4x(bg)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff623f-09d5-4a95-96f6-9a173586df3f",
   "metadata": {},
   "source": [
    "### Upsampling\n",
    "\n",
    "My image is too small for my screen. For example, suppose beans is 150x150, but I want to display the image in 600x600 pixels. What should I do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc232213-5c8a-41b9-9b73-53b4bad3df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans150 = filtering.down_4x(bg)\n",
    "util.imshow_truesize(beans150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41483a31-3a19-4518-9b6a-32c59bc7c1d5",
   "metadata": {},
   "source": [
    "See naive version preimplemented in `filtering.up_2x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3aba3-4a7d-4496-829f-d6f885e3eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_truesize(filtering.up_2x(beans150, interp=\"none\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de18e4f-a9a0-47ce-accd-6a724bcb16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_truesize(filtering.up_2x(beans150, interp=\"nn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c1902-84c7-49cc-a013-6e6e8ea210b7",
   "metadata": {},
   "source": [
    "**Whiteboard:** Filtering view of upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc890945-1eda-4c44-afed-a442cdecf840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: implement reconstruction filtering version in up_2x\n",
    "# - Gaussian reconstruction filter\n",
    "# - Linear reconstruction filter\n",
    "util.imshow_truesize(filtering.up_4x(beans150, interp=\"gaussian\"))\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
